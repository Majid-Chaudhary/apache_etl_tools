version: "3.7"

services:
  postgres:
    image: postgres:13
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: Delta_12345678
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - airflow_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:6-alpine
    container_name: airflow_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - airflow_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  airflow-init:
    image: apache/airflow:2.7.3
    container_name: airflow_init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Delta_12345678@postgres:5432/airflow
    entrypoint: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    networks:
      - airflow_net

  airflow-webserver:
    image: apache/airflow:2.7.3
    container_name: airflow_webserver
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth"
      AIRFLOW__UI__AUTH_REQUIRE_LOGIN: "True"
      AIRFLOW__USERS__DEFAULT_ROLE: Admin
      AIRFLOW__USERS__ADMIN_USERNAME: admin
      AIRFLOW__USERS__ADMIN_PASSWORD: admin
      AIRFLOW__USERS__ADMIN_FIRSTNAME: Admin
      AIRFLOW__USERS__ADMIN_LASTNAME: User
      AIRFLOW__USERS__ADMIN_EMAIL: admin@example.com
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
    command: >
      bash -c "
      pip install psycopg2-binary cx_Oracle airflow-hop-plugin-custom dbt-postgres &&
      airflow webserver
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - airflow_net

  airflow-scheduler:
    image: apache/airflow:2.7.3
    container_name: airflow_scheduler
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
    command: >
      bash -c "
      pip install dbt-postgres &&
      airflow scheduler
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    networks:
      - airflow_net

  airflow-worker:
    image: apache/airflow:2.7.3
    container_name: airflow_worker
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres:Delta_12345678@postgres:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    command: >
      bash -c "
      pip install dbt-postgres &&
      celery worker
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    networks:
      - airflow_net

volumes:
  postgres_data:
  redis_data:

networks:
  airflow_net:
    driver: bridge
